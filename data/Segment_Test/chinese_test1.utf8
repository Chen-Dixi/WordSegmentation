也就是说本来想用一个神经网络拟合 y 的，现在变成了用神经网络拟合 y−x 了，其中 x,y 都是向量（张量）。这样做的好处是梯度不容易消失，能训练深层网络，让信息多通道传输，等等。可逆的意思就是 x+g(x)是一个一一映射，也就是说每个 x 只有一个 y 与之对应，反过来也是，换言之我们理论中可以从中解出反函数x=h(y)来。
背景就不多说了，但是要说明一点，我们在分类问题中用的广义上的 ResNet，是允许通过 1×1 卷积改变维度的，但这里的 ResNet 指的是不改变维度的 ResNet，也就是说 x,y 的大小保持一样。