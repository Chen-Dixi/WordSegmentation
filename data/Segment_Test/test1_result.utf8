也就是说 本来 想 用 一个 神经 网络 拟 合y 的 ， 现在 变成 了 用 神经 网络 拟 合y −x 了 ， 其中 x ,y 都 是 向量 （ 张 量 ） 。 这样 做 的 好处 是 梯度 不 容易 消失 ， 能 训练 深层 网络 ， 让 信息 多 通道 传输 ， 等等 。 可 逆 的 意思 就 是 x+ g( x) 是 一个 一一映射 ， 也就是说 每个 x 只 有 一个 y 与 之 对 应 ， 反过来 也 是 ， 换言 之 我们 理论 中 可以 从中 解出 反函 数x =h (y ) 来 。 
背景 就 不 多 说 了 ， 但是 要 说明 一点 ， 我们 在 分类 问题 中用 的 广义 上 的 Re sN et ， 是 允许 通过 1× 1卷 积 改变 维度 的 ， 但 这里 的 Re sN et指 的 是 不 改变 维度 的 Re sN et ， 也就是说 x,y 的 大小 保持 一样 。 
